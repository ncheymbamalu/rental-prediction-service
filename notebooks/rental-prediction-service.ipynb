{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[00mLICENSE\u001b[0m\n",
      "├── \u001b[00mMakefile\u001b[0m\n",
      "├── \u001b[00mREADME.md\u001b[0m\n",
      "├── \u001b[01;34martifacts\u001b[0m\n",
      "│   └── \u001b[00mmodel.pkl\u001b[0m\n",
      "├── \u001b[00mconfig.yaml\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   └── \u001b[00mraw.parquet\u001b[0m\n",
      "├── \u001b[01;34mlogs\u001b[0m\n",
      "│   └── \u001b[00m10_14_2024_15_52_14.log\u001b[0m\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\n",
      "│   └── \u001b[00mrental-prediction-service.ipynb\u001b[0m\n",
      "├── \u001b[00mpoetry.lock\u001b[0m\n",
      "├── \u001b[00mpyproject.toml\u001b[0m\n",
      "├── \u001b[01;34msrc\u001b[0m\n",
      "│   ├── \u001b[00m__init__.py\u001b[0m\n",
      "│   ├── \u001b[00mapp.py\u001b[0m\n",
      "│   ├── \u001b[00mconfig.py\u001b[0m\n",
      "│   ├── \u001b[00mdata.py\u001b[0m\n",
      "│   ├── \u001b[00mdatabase.py\u001b[0m\n",
      "│   ├── \u001b[00mlogger.py\u001b[0m\n",
      "│   ├── \u001b[00mmodel.py\u001b[0m\n",
      "│   ├── \u001b[00mmodel_builder.py\u001b[0m\n",
      "│   ├── \u001b[00mmodel_inference.py\u001b[0m\n",
      "│   ├── \u001b[00mrun_model_builder.py\u001b[0m\n",
      "│   └── \u001b[00mrun_model_inference.py\u001b[0m\n",
      "└── \u001b[01;34mtests\u001b[0m\n",
      "    └── \u001b[00m__init__.py\u001b[0m\n",
      "\n",
      "7 directories, 22 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# delete all '__pycache__' directories throughout the project\n",
    "cd ..\n",
    "rm -rf `find . -type d -name __pycache__`\n",
    "\n",
    "# output the file structure from the project's root directory\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Dependencies`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# rental-prediction-service modules\n",
    "from src.data import encode_neighborhood_ids, preprocess_data\n",
    "from src.database import read_table\n",
    "from src.model import compute_rsquared, split_data\n",
    "from src.model_inference import ModelInferenceService\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pd.DataFrame and pd.Series display options\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Data ingestion and pre-processing`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "read_table().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processed data\n",
    "read_table().pipe(preprocess_data).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning-ready data\n",
    "# NOTE: the 'neighborhood_id' feature has been encoded\n",
    "read_table().pipe(preprocess_data).pipe(encode_neighborhood_ids).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Data splitting`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the machine learning-ready data into train, validation, and test sets\n",
    "Xtrain, Xval, Xtest, ytrain, yval, ytest = (\n",
    "    read_table()\n",
    "    .pipe(preprocess_data)\n",
    "    .pipe(encode_neighborhood_ids)\n",
    "    .pipe(split_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Model building`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a base model to the train set\n",
    "model: XGBRegressor = XGBRegressor(base_score=0.5, n_jobs=-1)\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Model evaluation`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the base model's test set R²\n",
    "compute_rsquared(ytest, model.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Hyperparameter tuning`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter search space\n",
    "# NOTE: hyperparameters are optimized on a parameter-by-parameter basis, that is, ...\n",
    "# 'n_estimators' is optimized 1st, then 'max_depth', then 'learning_rate' etc. \n",
    "search_space: dict[str, list[float | int]] = {\n",
    "    # \"n_estimators\": [100, 200, 500], # R²: \n",
    "    # \"max_depth\": [3, 6, 10], # R²: \n",
    "    # \"learning_rate\": [0.05, 0.1, 0.2, 0.3], # R²: \n",
    "    # \"gamma\": [0.01, 0.1, 1], # R²: \n",
    "    # \"min_child_weight\": [0, 5, 20, 50] # R²: \n",
    "}\n",
    "\n",
    "# instantiate an object of type, 'GridSearchCV'\n",
    "gscv: GridSearchCV = GridSearchCV(\n",
    "    estimator=XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.3,\n",
    "        gamma=0.1,\n",
    "        base_score=0.5,\n",
    "        n_jobs=-1\n",
    "        ),\n",
    "    param_grid=search_space,\n",
    "    scoring=\"r2\",\n",
    "    refit=\"r2\",\n",
    "    cv=5,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# fit the 'gscv' object to the train set\n",
    "gscv.fit(Xtrain, ytrain)\n",
    "\n",
    "# output the validation set R² and 'best' parameters\n",
    "display(\n",
    "    compute_rsquared(yval, gscv.best_estimator_.predict(Xval)),\n",
    "    gscv.best_params_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the 'gscv' object's 'best' model\n",
    "best_model: XGBRegressor = gscv.best_estimator_\n",
    "\n",
    "# fit the 'best' model to the train set and evaluate it on the validation set\n",
    "best_model.early_stopping_rounds = 20\n",
    "best_model.fit(Xtrain, ytrain, eval_set=[(Xval, yval)], verbose=False)\n",
    "\n",
    "# output the 'best' model's test set R²\n",
    "# NOTE: hyperparameter tuning didn't make a difference, that is, ...\n",
    "# the 'best' model's test set R², 0.82, is identical to the base model's test set R²\n",
    "compute_rsquared(ytest, best_model.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Inference`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input record\n",
    "record: dict[str, float | int | str] = {\n",
    "    \"year_built\": 2016,\n",
    "    \"area\": 105.0,\n",
    "    \"bedrooms\": 3,\n",
    "    \"bathrooms\": 2.0,\n",
    "    \"furnished\": \"no\",\n",
    "    \"storage\": \"no\",\n",
    "    \"garage\": \"yes\",\n",
    "    \"parking\": \"yes\",\n",
    "    \"balcony\": \"yes\",\n",
    "    \"garden_size\": 10.0,\n",
    "    \"neighborhood_id\": 10\n",
    "}\n",
    "\n",
    "# instantiate an object of type, 'ModelInferenceService'\n",
    "service: ModelInferenceService = ModelInferenceService()\n",
    "\n",
    "# load the trained model \n",
    "service.load_model()\n",
    "\n",
    "# output the prediction\n",
    "service.predict(record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
